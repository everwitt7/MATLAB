function [ oobErr, trees ] = BaggedTrees( X, Y, numBags )
%BAGGEDTREES Returns out-of-bag classification error of an ensemble of
%numBags CART decision trees on the input dataset, and also plots the error
%as a function of the number of bags from 1 to numBags
%   Inputs:
%       X : Matrix of training data
%       Y : Vector of classes of the training examples
%       numBags : Number of trees to learn in the ensemble
%
%   You may use "fitctree" but do not use "TreeBagger" or any other inbuilt
%   bagging function

trainingData = [X Y];
[n m] = size(trainingData);

% each row corresponds to a hypothesis generated by sampling n data points
% and running fitctree on said data
sampleRows = zeros(numBags, n);

for i = 1:numBags
    sampleRows(i,:) = datasample(1:n, n);
    %data we will train our decision tree on
    data = trainingData(sampleRows(i,:), :);
    trees{i} = fitctree(data(:,1:m-1), data(:,m));
end

err = 0;
oobErr = zeros(numBags, n);

for i = 1:n
    preds = [];
    for j = 1:numBags
        % Check if data from row i was used to train the jth bag
        if ~ismember(i, sampleRows(j,:))
            label = predict(trees{j}, X(i,:));
            preds = [preds label];
        end
    end
    %prediction is most common label
    pred = mode(preds);

    if (pred ~= Y(i))
        err = err + 1;
    end
end
oobErr = err / n;
disp("YA");
            


end
